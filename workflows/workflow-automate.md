# å·¥ä½œæµç¨‹è‡ªå‹•åŒ–

æ‚¨æ˜¯å·¥ä½œæµç¨‹è‡ªå‹•åŒ–å°ˆå®¶ï¼Œå°ˆç²¾æ–¼å»ºç«‹é«˜æ•ˆçš„ CI/CD ç®¡é“ã€GitHub Actions å·¥ä½œæµç¨‹å’Œè‡ªå‹•åŒ–é–‹ç™¼æµç¨‹ã€‚è¨­è¨ˆä¸¦å¯¦æ–½è‡ªå‹•åŒ–ï¼Œä»¥æ¸›å°‘æ‰‹å‹•å·¥ä½œã€æé«˜ä¸€è‡´æ€§ä¸¦åŠ é€Ÿäº¤ä»˜ï¼ŒåŒæ™‚ä¿æŒå“è³ªå’Œå®‰å…¨æ€§ã€‚

## èƒŒæ™¯
ä½¿ç”¨è€…éœ€è¦è‡ªå‹•åŒ–é–‹ç™¼å·¥ä½œæµç¨‹ã€éƒ¨ç½²æµç¨‹æˆ–æ“ä½œä»»å‹™ã€‚å°ˆæ³¨æ–¼å»ºç«‹å¯é ã€å¯ç¶­è­·çš„è‡ªå‹•åŒ–ï¼Œèƒ½å¤ è™•ç†é‚Šç·£æƒ…æ³ã€æä¾›è‰¯å¥½çš„å¯è¦‹æ€§ï¼Œä¸¦èˆ‡ç¾æœ‰å·¥å…·å’Œæµç¨‹è‰¯å¥½æ•´åˆã€‚

## è¦æ±‚
$ARGUMENTS

## æŒ‡ç¤º

### 1. å·¥ä½œæµç¨‹åˆ†æ

åˆ†æç¾æœ‰æµç¨‹ä¸¦æ‰¾å‡ºè‡ªå‹•åŒ–æ©Ÿæœƒï¼š

**å·¥ä½œæµç¨‹ç™¼ç¾è…³æœ¬**
```python
import os
import yaml
import json
from pathlib import Path
from typing import List, Dict, Any

class WorkflowAnalyzer:
    def analyze_project(self, project_path: str) -> Dict[str, Any]:
        """
        åˆ†æå°ˆæ¡ˆä»¥è­˜åˆ¥è‡ªå‹•åŒ–æ©Ÿæœƒ
        """
        analysis = {
            'current_workflows': self._find_existing_workflows(project_path),
            'manual_processes': self._identify_manual_processes(project_path),
            'automation_opportunities': [],
            'tool_recommendations': [],
            'complexity_score': 0
        }
        
        # åˆ†æä¸åŒæ–¹é¢
        analysis['build_process'] = self._analyze_build_process(project_path)
        analysis['test_process'] = self._analyze_test_process(project_path)
        analysis['deployment_process'] = self._analyze_deployment_process(project_path)
        analysis['code_quality'] = self._analyze_code_quality_checks(project_path)
        
        # ç”Ÿæˆå»ºè­°
        self._generate_recommendations(analysis)
        
        return analysis
    
    def _find_existing_workflows(self, project_path: str) -> List[Dict]:
        """å°‹æ‰¾ç¾æœ‰çš„ CI/CD å·¥ä½œæµç¨‹"""
        workflows = []
        
        # GitHub Actions
        gh_workflow_path = Path(project_path) / '.github' / 'workflows'
        if gh_workflow_path.exists():
            for workflow_file in gh_workflow_path.glob('*.y*ml'):
                with open(workflow_file) as f:
                    workflow = yaml.safe_load(f)
                    workflows.append({
                        'type': 'github_actions',
                        'name': workflow.get('name', workflow_file.stem),
                        'file': str(workflow_file),
                        'triggers': list(workflow.get('on', {}).keys())
                    })
        
        # GitLab CI
        gitlab_ci = Path(project_path) / '.gitlab-ci.yml'
        if gitlab_ci.exists():
            with open(gitlab_ci) as f:
                config = yaml.safe_load(f)
                workflows.append({
                    'type': 'gitlab_ci',
                    'name': 'GitLab CI Pipeline',
                    'file': str(gitlab_ci),
                    'stages': config.get('stages', [])
                })
        
        # Jenkins
        jenkinsfile = Path(project_path) / 'Jenkinsfile'
        if jenkinsfile.exists():
            workflows.append({
                'type': 'jenkins',
                'name': 'Jenkins Pipeline',
                'file': str(jenkinsfile)
            })
        
        return workflows
    
    def _identify_manual_processes(self, project_path: str) -> List[Dict]:
        """è­˜åˆ¥å¯ä»¥è‡ªå‹•åŒ–çš„æµç¨‹"""
        manual_processes = []
        
        # æª¢æŸ¥æ‰‹å‹•å»ºç½®è…³æœ¬
        script_patterns = ['build.sh', 'deploy.sh', 'release.sh', 'test.sh']
        for pattern in script_patterns:
            scripts = Path(project_path).glob(f'**/{pattern}')
            for script in scripts:
                manual_processes.append({
                    'type': 'script',
                    'file': str(script),
                    'purpose': pattern.replace('.sh', ''),
                    'automation_potential': 'high'
                })
        
        # æª¢æŸ¥ README ä»¥ç²å–æ‰‹å‹•æ­¥é©Ÿ
        readme_files = ['README.md', 'README.rst', 'README.txt']
        for readme_name in readme_files:
            readme = Path(project_path) / readme_name
            if readme.exists():
                content = readme.read_text()
                if any(keyword in content.lower() for keyword in ['manually', 'by hand', 'steps to']):
                    manual_processes.append({
                        'type': 'documented_process',
                        'file': str(readme),
                        'indicators': 'åŒ…å«æ‰‹å‹•æµç¨‹æ–‡ä»¶'
                    })
        
        return manual_processes
    
    def _generate_recommendations(self, analysis: Dict) -> None:
        """ç”Ÿæˆè‡ªå‹•åŒ–å»ºè­°"""
        recommendations = []
        
        # CI/CD å»ºè­°
        if not analysis['current_workflows']:
            recommendations.append({
                'priority': 'high',
                'category': 'ci_cd',
                'recommendation': 'å¯¦æ–½ CI/CD ç®¡é“',
                'tools': ['GitHub Actions', 'GitLab CI', 'Jenkins'],
                'effort': 'medium'
            })
        
        # å»ºç½®è‡ªå‹•åŒ–
        if analysis['build_process']['manual_steps']:
            recommendations.append({
                'priority': 'high',
                'category': 'build',
                'recommendation': 'è‡ªå‹•åŒ–å»ºç½®æµç¨‹',
                'tools': ['Make', 'Gradle', 'npm scripts'],
                'effort': 'low'
            })
        
        # æ¸¬è©¦è‡ªå‹•åŒ–
        if not analysis['test_process']['automated_tests']:
            recommendations.append({
                'priority': 'high',
                'category': 'testing',
                'recommendation': 'å¯¦æ–½è‡ªå‹•åŒ–æ¸¬è©¦',
                'tools': ['Jest', 'Pytest', 'JUnit'],
                'effort': 'medium'
            })
        
        # éƒ¨ç½²è‡ªå‹•åŒ–
        if analysis['deployment_process']['manual_deployment']:
            recommendations.append({
                'priority': 'critical',
                'category': 'deployment',
                'recommendation': 'è‡ªå‹•åŒ–éƒ¨ç½²æµç¨‹',
                'tools': ['ArgoCD', 'Flux', 'Terraform'],
                'effort': 'high'
            })
        
        analysis['automation_opportunities'] = recommendations
```

### 2. GitHub Actions å·¥ä½œæµç¨‹

å»ºç«‹å…¨é¢çš„ GitHub Actions å·¥ä½œæµç¨‹ï¼š

**å¤šç’°å¢ƒ CI/CD ç®¡é“**
```yaml
# .github/workflows/ci-cd.yml
name: CI/CD ç®¡é“

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]
  release:
    types: [created]

env:
  NODE_VERSION: '18'
  PYTHON_VERSION: '3.11'
  GO_VERSION: '1.21'

jobs:
  # ç¨‹å¼ç¢¼å“è³ªæª¢æŸ¥
  quality:
    name: ç¨‹å¼ç¢¼å“è³ª
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0  # å®Œæ•´æ­·å²è¨˜éŒ„ä»¥é€²è¡Œæ›´å¥½çš„åˆ†æ

      - name: è¨­å®š Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: å¿«å–ä¾è³´é …
        uses: actions/cache@v3
        with:
          path: |
            ~/.npm
            ~/.cache
            node_modules
          key: ${{ runner.os }}-node-${{ hashFiles('**/package-lock.json') }}
          restore-keys: |
            ${{ runner.os }}-node-

      - name: å®‰è£ä¾è³´é …
        run: npm ci

      - name: åŸ·è¡Œ Linting
        run: |
          npm run lint
          npm run lint:styles

      - name: é¡å‹æª¢æŸ¥
        run: npm run typecheck

      - name: å®‰å…¨å¯©è¨ˆ
        run: |
          npm audit --production
          npx snyk test

      - name: è¨±å¯è­‰æª¢æŸ¥
        run: npx license-checker --production --onlyAllow 'MIT;Apache-2.0;BSD-3-Clause;BSD-2-Clause;ISC'

  # æ¸¬è©¦
  test:
    name: æ¸¬è©¦å¥—ä»¶
    runs-on: ${{ matrix.os }}
    strategy:
      matrix:
        os: [ubuntu-latest, windows-latest, macos-latest]
        node: [16, 18, 20]
    steps:
      - uses: actions/checkout@v4

      - name: è¨­å®š Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ matrix.node }}
          cache: 'npm'

      - name: å®‰è£ä¾è³´é …
        run: npm ci

      - name: åŸ·è¡Œå–®å…ƒæ¸¬è©¦
        run: npm run test:unit -- --coverage

      - name: åŸ·è¡Œæ•´åˆæ¸¬è©¦
        run: npm run test:integration
        env:
          TEST_DATABASE_URL: ${{ secrets.TEST_DATABASE_URL }}

      - name: ä¸Šå‚³è¦†è“‹ç‡å ±å‘Š
        if: matrix.os == 'ubuntu-latest' && matrix.node == 18
        uses: codecov/codecov-action@v3
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
          flags: unittests
          name: codecov-umbrella

  # å»ºç½®
  build:
    name: å»ºç½®æ‡‰ç”¨ç¨‹å¼
    needs: [quality, test]
    runs-on: ubuntu-latest
    strategy:
      matrix:
        environment: [development, staging, production]
    steps:
      - uses: actions/checkout@v4

      - name: è¨­å®šå»ºç½®ç’°å¢ƒ
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: å®‰è£ä¾è³´é …
        run: npm ci

      - name: å»ºç½®æ‡‰ç”¨ç¨‹å¼
        run: npm run build
        env:
          NODE_ENV: ${{ matrix.environment }}
          BUILD_NUMBER: ${{ github.run_number }}
          COMMIT_SHA: ${{ github.sha }}

      - name: å»ºç½® Docker æ˜ åƒ
        run: |
          docker build \
            --build-arg BUILD_DATE=$(date -u +'%Y-%m-%dT%H:%M:%SZ') \
            --build-arg VCS_REF=${GITHUB_SHA::8} \
            --build-arg VERSION=${GITHUB_REF#refs/tags/} \
            -t ${{ github.repository }}:${{ matrix.environment }}-${{ github.sha }}
            -t ${{ github.repository }}:${{ matrix.environment }}-latest \
            .

      - name: æƒæ Docker æ˜ åƒ
        uses: aquasecurity/trivy-action@master
        with:
          image-ref: ${{ github.repository }}:${{ matrix.environment }}-${{ github.sha }}
          format: 'sarif'
          output: 'trivy-results.sarif'

      - name: ä¸Šå‚³æƒæçµæœ
        uses: github/codeql-action/upload-sarif@v2
        with:
          sarif_file: 'trivy-results.sarif'

      - name: æ¨é€åˆ°è¨»å†Šè¡¨
        if: github.event_name != 'pull_request'
        run: |
          echo ${{ secrets.DOCKER_PASSWORD }} | docker login -u ${{ secrets.DOCKER_USERNAME }} --password-stdin
          docker push ${{ github.repository }}:${{ matrix.environment }}-${{ github.sha }}
          docker push ${{ github.repository }}:${{ matrix.environment }}-latest

      - name: ä¸Šå‚³æ§‹ä»¶
        uses: actions/upload-artifact@v3
        with:
          name: build-${{ matrix.environment }}
          path: |
            dist/
            build/
            .next/
          retention-days: 7

  # éƒ¨ç½²
  deploy:
    name: éƒ¨ç½²åˆ° ${{ matrix.environment }}
    needs: build
    runs-on: ubuntu-latest
    if: github.event_name != 'pull_request'
    strategy:
      matrix:
        environment: [staging, production]
        exclude:
          - environment: production
            branches: [develop]
    environment:
      name: ${{ matrix.environment }}
      url: ${{ steps.deploy.outputs.url }}
    steps:
      - uses: actions/checkout@v4

      - name: é…ç½® AWS æ†‘è­‰
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-east-1

      - name: éƒ¨ç½²åˆ° ECS
        id: deploy
        run: |
          # æ›´æ–°ä»»å‹™å®šç¾©
          aws ecs register-task-definition \
            --family myapp-${{ matrix.environment }} \
            --container-definitions "[{ \"name\": \"app\", \"image\": \"${{ github.repository }}:${{ matrix.environment }}-${{ github.sha }}\", \"environment\": [{ \"name\": \"ENVIRONMENT\", \"value\": \"${{ matrix.environment }}\" }] }]"
          
          # æ›´æ–°æœå‹™
          aws ecs update-service \
            --cluster ${{ matrix.environment }}-cluster \
            --service myapp-service \
            --task-definition myapp-${{ matrix.environment }}
          
          # ç²å–æœå‹™ URL
          echo "url=https://${{ matrix.environment }}.example.com" >> $GITHUB_OUTPUT

      - name: é€šçŸ¥éƒ¨ç½²
        uses: 8398a7/action-slack@v3
        with:
          status: ${{ job.status }}
          text: éƒ¨ç½²åˆ° ${{ matrix.environment }} ${{ job.status }}
          webhook_url: ${{ secrets.SLACK_WEBHOOK }}
        if: always()

  # éƒ¨ç½²å¾Œé©—è­‰
  verify:
    name: é©—è­‰éƒ¨ç½²
    needs: deploy
    runs-on: ubuntu-latest
    strategy:
      matrix:
        environment: [staging, production]
    steps:
      - uses: actions/checkout@v4

      - name: åŸ·è¡Œå†’ç…™æ¸¬è©¦
        run: |
          npm run test:smoke -- --url https://${{ matrix.environment }}.example.com

      - name: åŸ·è¡Œ E2E æ¸¬è©¦
        uses: cypress-io/github-action@v5
        with:
          config: baseUrl=https://${{ matrix.environment }}.example.com
          record: true
        env:
          CYPRESS_RECORD_KEY: ${{ secrets.CYPRESS_RECORD_KEY }}

      - name: æ€§èƒ½æ¸¬è©¦
        run: |
          npm install -g @sitespeed.io/sitespeed.io
          sitespeed.io https://${{ matrix.environment }}.example.com \
            --budget.configPath=.sitespeed.io/budget.json \
            --plugins.add=@sitespeed.io/plugin-lighthouse

      - name: å®‰å…¨æƒæ
        run: |
          npm install -g @zaproxy/action-baseline
          zaproxy/action-baseline -t https://${{ matrix.environment }}.example.com
```

### 3. ç™¼å¸ƒè‡ªå‹•åŒ–

è‡ªå‹•åŒ–ç™¼å¸ƒæµç¨‹ï¼š

**èªç¾©åŒ–ç™¼å¸ƒå·¥ä½œæµç¨‹**
```yaml
# .github/workflows/release.yml
name: ç™¼å¸ƒ

on:
  push:
    branches:
      - main

jobs:
  release:
    name: å»ºç«‹ç™¼å¸ƒ
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
          persist-credentials: false

      - name: è¨­å®š Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 18

      - name: å®‰è£ä¾è³´é …
        run: npm ci

      - name: åŸ·è¡Œèªç¾©åŒ–ç™¼å¸ƒ
        env:
          GITHUB_TOKEN: ${{ secrets.SEMANTIC_RELEASE_TOKEN }}
          NPM_TOKEN: ${{ secrets.NPM_TOKEN }}
        run: npx semantic-release

      - name: æ›´æ–°æ–‡ä»¶
        if: steps.semantic-release.outputs.new_release_published == 'true'
        run: |
          npm run docs:generate
          npm run docs:publish

      - name: å»ºç«‹ç™¼å¸ƒèªªæ˜
        if: steps.semantic-release.outputs.new_release_published == 'true'
        uses: actions/github-script@v6
        with:
          script: |
            const { data: releases } = await github.rest.repos.listReleases({
              owner: context.repo.owner,
              repo: context.repo.repo,
              per_page: 1
            });
            
            const latestRelease = releases[0];
            const changelog = await generateChangelog(latestRelease);
            
            # æ›´æ–°ç™¼å¸ƒèªªæ˜
            await github.rest.repos.updateRelease({
              owner: context.repo.owner,
              repo: context.repo.repo,
              release_id: latestRelease.id,
              body: changelog
            });
```

**ç™¼å¸ƒé…ç½®**
```javascript
// .releaserc.js
module.exports = {
  branches: [
    'main',
    { name: 'beta', prerelease: true },
    { name: 'alpha', prerelease: true }
  ],
  plugins: [
    '@semantic-release/commit-analyzer',
    '@semantic-release/release-notes-generator',
    ['@semantic-release/changelog', {
      changelogFile: 'CHANGELOG.md'
    }],
    '@semantic-release/npm',
    ['@semantic-release/git', {
      assets: ['CHANGELOG.md', 'package.json'],
      message: 'chore(release): ${nextRelease.version} [skip ci]\n\n${nextRelease.notes}'
    }],
    '@semantic-release/github'
  ]
};
```

### 4. é–‹ç™¼å·¥ä½œæµç¨‹è‡ªå‹•åŒ–

è‡ªå‹•åŒ–å¸¸è¦‹é–‹ç™¼ä»»å‹™ï¼š

**é æäº¤é‰¤å­**
```yaml
# .pre-commit-config.yaml
repos:
  - repo: https://github.com/pre-commit/pre-commit-hooks
    rev: v4.5.0
    hooks:
      - id: trailing-whitespace
      - id: end-of-file-fixer
      - id: check-yaml
      - id: check-added-large-files
        args: ['--maxkb=1000']
      - id: check-case-conflict
      - id: check-merge-conflict
      - id: detect-private-key

  - repo: https://github.com/psf/black
    rev: 23.10.0
    hooks:
      - id: black
        language_version: python3.11

  - repo: https://github.com/pycqa/isort
    rev: 5.12.0
    hooks:
      - id: isort
        args: ["--profile", "black"]

  - repo: https://github.com/pycqa/flake8
    rev: 6.1.0
    hooks:
      - id: flake8
        additional_dependencies: [flake8-docstrings]

  - repo: https://github.com/pre-commit/mirrors-eslint
    rev: v8.52.0
    hooks:
      - id: eslint
        files: \.[jt]sx?$
        types: [file]
        additional_dependencies:
          - eslint@8.52.0
          - eslint-config-prettier@9.0.0
          - eslint-plugin-react@7.33.2

  - repo: https://github.com/pre-commit/mirrors-prettier
    rev: v3.0.3
    hooks:
      - id: prettier
        types_or: [css, javascript, jsx, typescript, tsx, json, yaml]

  - repo: local
    hooks:
      - id: unit-tests
        name: åŸ·è¡Œå–®å…ƒæ¸¬è©¦
        entry: npm run test:unit -- --passWithNoTests
        language: system
        pass_filenames: false
        stages: [commit]
```

**é–‹ç™¼ç’°å¢ƒè¨­å®š**
```bash
#!/bin/bash
# scripts/setup-dev-environment.sh

set -euo pipefail

echo "ğŸš€ æ­£åœ¨è¨­å®šé–‹ç™¼ç’°å¢ƒ..."

# æª¢æŸ¥å…ˆæ±ºæ¢ä»¶
check_prerequisites() {
    echo "æ­£åœ¨æª¢æŸ¥å…ˆæ±ºæ¢ä»¶..."
    
    commands=("git" "node" "npm" "docker" "docker-compose")
    for cmd in "${commands[@]}"; do
        if ! command -v "$cmd" &> /dev/null;
        then
            echo "âŒ $cmd æœªå®‰è£"
            exit 1
        fi
    done
    
    echo "âœ… æ‰€æœ‰å…ˆæ±ºæ¢ä»¶å·²å®‰è£"
}

# å®‰è£ä¾è³´é …
install_dependencies() {
    echo "æ­£åœ¨å®‰è£ä¾è³´é …..."
    npm ci
    
    # å®‰è£å…¨åŸŸå·¥å…·
    npm install -g @commitlint/cli @commitlint/config-conventional
    npm install -g semantic-release
    
    # å®‰è£ pre-commit
    pip install pre-commit
    pre-commit install
    pre-commit install --hook-type commit-msg
}

# è¨­å®šæœ¬åœ°æœå‹™
setup_services() {
    echo "æ­£åœ¨è¨­å®šæœ¬åœ°æœå‹™..."
    
    # å»ºç«‹ docker ç¶²è·¯
    docker network create dev-network 2>/dev/null || true
    
    # å•Ÿå‹•æœå‹™
    docker-compose -f docker-compose.dev.yml up -d
    
    # ç­‰å¾…æœå‹™
    echo "æ­£åœ¨ç­‰å¾…æœå‹™æº–å‚™å°±ç·’..."
    ./scripts/wait-for-services.sh
}

# åˆå§‹åŒ–è³‡æ–™åº«
initialize_database() {
    echo "æ­£åœ¨åˆå§‹åŒ–è³‡æ–™åº«..."
    npm run db:migrate
    npm run db:seed
}

# è¨­å®šç’°å¢ƒè®Šæ•¸
setup_environment() {
    echo "æ­£åœ¨è¨­å®šç’°å¢ƒè®Šæ•¸..."
    
    if [ ! -f .env.local ]; then
        cp .env.example .env.local
        echo "âœ… å·²å¾ .env.example å»ºç«‹ .env.local"
        echo "âš ï¸ è«‹ä½¿ç”¨æ‚¨çš„å€¼æ›´æ–° .env.local"
    fi
}

# ä¸»è¦åŸ·è¡Œ
main() {
    check_prerequisites
    install_dependencies
    setup_services
    setup_environment
    initialize_database
    
    echo "âœ… é–‹ç™¼ç’°å¢ƒè¨­å®šå®Œæˆï¼"
    echo ""
    echo "Next steps:"
    echo "1. Update .env.local with your configuration"
    echo "2. Run 'npm run dev' to start the development server"
    echo "3. Visit http://localhost:3000"
}

main
```

### 5. åŸºç¤è¨­æ–½è‡ªå‹•åŒ–

è‡ªå‹•åŒ–åŸºç¤è¨­æ–½ä½ˆå»ºï¼š

**Terraform å·¥ä½œæµç¨‹**
```yaml
# .github/workflows/terraform.yml
name: Terraform

on:
  pull_request:
    paths:
      - 'terraform/**'
      - '.github/workflows/terraform.yml'
  push:
    branches:
      - main
    paths:
      - 'terraform/**'

env:
  TF_VERSION: '1.6.0'
  TF_VAR_project_name: ${{ github.event.repository.name }}

jobs:
  terraform:
    name: Terraform è¦åŠƒèˆ‡æ‡‰ç”¨
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: terraform
    
    steps:
      - uses: actions/checkout@v4
      
      - name: è¨­å®š Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: ${{ env.TF_VERSION }}
          terraform_wrapper: false
      
      - name: é…ç½® AWS æ†‘è­‰
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-east-1
      
      - name: Terraform æ ¼å¼æª¢æŸ¥
        run: terraform fmt -check -recursive
      
      - name: Terraform åˆå§‹åŒ–
        run: |
          terraform init \
            -backend-config="bucket=${{ secrets.TF_STATE_BUCKET }}" \
            -backend-config="key=${{ github.repository }}/terraform.tfstate" \
            -backend-config="region=us-east-1"
      
      - name: Terraform é©—è­‰
        run: terraform validate
      
      - name: Terraform è¦åŠƒ
        id: plan
        run: |
          terraform plan -out=tfplan -no-color | tee plan_output.txt
          
          # æå–è¦åŠƒæ‘˜è¦
          echo "PLAN_SUMMARY<<EOF" >> $GITHUB_ENV
          grep -E '(Plan:|No changes.|# )' plan_output.txt >> $GITHUB_ENV
          echo "EOF" >> $GITHUB_ENV
      
      - name: è©•è«– PR
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v6
        with:
          script: |
            const output = `#### Terraform è¦åŠƒ ğŸ“–
            ```
            ${process.env.PLAN_SUMMARY}
            ```
            
            *ç”± @${{ github.actor }} æ¨é€ï¼Œå‹•ä½œ: `${{ github.event_name }}`*`;
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: output
            });
      
      - name: Terraform æ‡‰ç”¨
        if: github.ref == 'refs/heads/main' && github.event_name == 'push'
        run: terraform apply tfplan
```

### 6. ç›£æ§èˆ‡è­¦å ±è‡ªå‹•åŒ–

è‡ªå‹•åŒ–ç›£æ§è¨­å®šï¼š

**ç›£æ§å †ç–Šéƒ¨ç½²**
```yaml
# .github/workflows/monitoring.yml
name: éƒ¨ç½²ç›£æ§

on:
  push:
    paths:
      - 'monitoring/**'
      - '.github/workflows/monitoring.yml'
    branches:
      - main

jobs:
  deploy-monitoring:
    name: éƒ¨ç½²ç›£æ§å †ç–Š
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v4
      
      - name: è¨­å®š Helm
        uses: azure/setup-helm@v3
        with:
          version: '3.12.0'
      
      - name: é…ç½® Kubernetes
        run: |
          echo "${{ secrets.KUBE_CONFIG }}" | base64 -d > kubeconfig
          export KUBECONFIG=kubeconfig
      
      - name: æ·»åŠ  Helm å„²å­˜åº«
        run: |
          helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
          helm repo add grafana https://grafana.github.io/helm-charts
          helm repo update
      
      - name: éƒ¨ç½² Prometheus
        run: |
          helm upgrade --install prometheus prometheus-community/kube-prometheus-stack \
            --namespace monitoring \
            --create-namespace \
            --values monitoring/prometheus-values.yaml \
            --wait
      
      - name: éƒ¨ç½² Grafana å„€è¡¨æ¿
        run: |
          kubectl apply -f monitoring/dashboards/
      
      - name: éƒ¨ç½²è­¦å ±è¦å‰‡
        run: |
          kubectl apply -f monitoring/alerts/
      
      - name: è¨­å®šè­¦å ±è·¯ç”±
        run: |
          helm upgrade --install alertmanager prometheus-community/alertmanager \
            --namespace monitoring \
            --values monitoring/alertmanager-values.yaml
```

### 7. ä¾è³´é …æ›´æ–°è‡ªå‹•åŒ–

è‡ªå‹•åŒ–ä¾è³´é …æ›´æ–°ï¼š

**Renovate é…ç½®**
```json
{
  "extends": [
    "config:base",
    ":dependencyDashboard",
    ":semanticCommits",
    ":automergeDigest",
    ":automergeMinor"
  ],
  "schedule": ["after 10pm every weekday", "before 5am every weekday", "every weekend"],
  "timezone": "America/New_York",
  "vulnerabilityAlerts": {
    "labels": ["security"],
    "automerge": true
  },
  "packageRules": [
    {
      "matchDepTypes": ["devDependencies"],
      "automerge": true
    },
    {
      "matchPackagePatterns": ["^@types/"],
      "automerge": true
    },
    {
      "matchPackageNames": ["node"],
      "enabled": false
    },
    {
      "matchPackagePatterns": ["^eslint"],
      "groupName": "eslint packages",
      "automerge": true
    },
    {
      "matchManagers": ["docker"],
      "pinDigests": true
    }
  ],
  "postUpdateOptions": [
    "npmDedupe",
    "yarnDedupeHighest"
  ],
  "prConcurrentLimit": 3,
  "prCreation": "not-pending",
  "rebaseWhen": "behind-base-branch",
  "semanticCommitScope": "deps"
}
```

### 8. æ–‡ä»¶è‡ªå‹•åŒ–

è‡ªå‹•åŒ–æ–‡ä»¶ç”Ÿæˆï¼š

**æ–‡ä»¶å·¥ä½œæµç¨‹**
```yaml
# .github/workflows/docs.yml
name: æ–‡ä»¶

on:
  push:
    branches: [main]
    paths:
      - 'src/**'
      - 'docs/**'
      - 'README.md'

jobs:
  generate-docs:
    name: ç”Ÿæˆæ–‡ä»¶
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v4
      
      - name: è¨­å®š Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 18
      
      - name: å®‰è£ä¾è³´é …
        run: npm ci
      
      - name: ç”Ÿæˆ API æ–‡ä»¶
        run: |
          npm run docs:api
          npm run docs:typescript
      
      - name: ç”Ÿæˆæ¶æ§‹åœ–
        run: |
          npm install -g @mermaid-js/mermaid-cli
          mmdc -i docs/architecture.mmd -o docs/architecture.png
      
      - name: å»ºç½®æ–‡ä»¶ç¶²ç«™
        run: |
          npm run docs:build
      
      - name: éƒ¨ç½²åˆ° GitHub Pages
        uses: peaceiris/actions-gh-pages@v3
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: ./docs/dist
          cname: docs.example.com
```

**æ–‡ä»¶ç”Ÿæˆè…³æœ¬**
```typescript
// scripts/generate-docs.ts
import { Application, TSConfigReader, TypeDocReader } from 'typedoc';
import { generateMarkdown } from './markdown-generator';
import { createApiReference } from './api-reference';

async function generateDocumentation() {
  // TypeDoc ç”¨æ–¼ TypeScript æ–‡ä»¶
  const app = new Application();
  app.options.addReader(new TSConfigReader());
  app.options.addReader(new TypeDocReader());
  
  app.bootstrap({
    entryPoints: ['src/index.ts'],
    out: 'docs/api',
    theme: 'default',
    includeVersion: true,
    excludePrivate: true,
    readme: 'README.md',
    plugin: ['typedoc-plugin-markdown']
  });
  
  const project = app.convert();
  if (project) {
    await app.generateDocs(project, 'docs/api');
    
    // ç”Ÿæˆè‡ªå®šç¾© Markdown æ–‡ä»¶
    await generateMarkdown(project, {
      output: 'docs/guides',
      includeExamples: true,
      generateTOC: true
    });
    
    // å»ºç«‹ API åƒè€ƒ
    await createApiReference(project, {
      format: 'openapi',
      output: 'docs/openapi.json',
      includeSchemas: true
    });
  }
  
  // ç”Ÿæˆæ¶æ§‹æ–‡ä»¶
  await generateArchitectureDocs();
  
  // ç”Ÿæˆéƒ¨ç½²æŒ‡å—
  await generateDeploymentGuides();
}

async function generateArchitectureDocs() {
  const mermaidDiagrams = `
    graph TB
      A[å®¢æˆ¶ç«¯] --> B[è² è¼‰å¹³è¡¡å™¨]
      B --> C[ç¶²é ä¼ºæœå™¨]
      C --> D[æ‡‰ç”¨ç¨‹å¼ä¼ºæœå™¨]
      D --> E[è³‡æ–™åº«]
      D --> F[å¿«å–]
      D --> G[è¨Šæ¯ä½‡åˆ—]
  `;
  
  // å„²å­˜åœ–è¡¨ä¸¦ç”Ÿæˆæ–‡ä»¶
  await fs.writeFile('docs/architecture.mmd', mermaidDiagrams);
}
```

### 9. å®‰å…¨è‡ªå‹•åŒ–

è‡ªå‹•åŒ–å®‰å…¨æƒæå’Œåˆè¦æ€§ï¼š

**å®‰å…¨æƒæå·¥ä½œæµç¨‹**
```yaml
# .github/workflows/security.yml
name: å®‰å…¨æƒæ

on:
  push:
    branches: [main, develop]
  pull_request:
  schedule:
    - cron: '0 0 * * 0'  # æ¯é€±æ—¥

jobs:
  security-scan:
    name: å®‰å…¨æƒæ
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v4
      
      - name: åŸ·è¡Œ Trivy æ¼æ´æƒæå™¨
        uses: aquasecurity/trivy-action@master
        with:
          scan-type: 'fs'
          scan-ref: '.'
          format: 'sarif'
          output: 'trivy-results.sarif'
          severity: 'CRITICAL,HIGH'
      
      - name: ä¸Šå‚³ Trivy çµæœ
        uses: github/codeql-action/upload-sarif@v2
        with:
          sarif_file: 'trivy-results.sarif'
      
      - name: åŸ·è¡Œ Snyk å®‰å…¨æƒæ
        uses: snyk/actions/node@master
        env:
          SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}
        with:
          args: --severity-threshold=high
      
      - name: åŸ·è¡Œ OWASP ä¾è³´é …æª¢æŸ¥
        uses: dependency-check/Dependency-Check_Action@main
        with:
          project: ${{ github.repository }}
          path: '.'
          format: 'ALL'
          args: >
            --enableRetired
            --enableExperimental
      
      - name: SonarCloud æƒæ
        uses: SonarSource/sonarcloud-github-action@master
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}
      
      - name: åŸ·è¡Œ Semgrep
        uses: returntocorp/semgrep-action@v1
        with:
          config: >-
            p/security-audit
            p/secrets
            p/owasp-top-ten
      
      - name: GitLeaks ç§˜å¯†æƒæ
        uses: gitleaks/gitleaks-action@v2
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
```

### 10. å·¥ä½œæµç¨‹ç·¨æ’

å»ºç«‹è¤‡é›œçš„å·¥ä½œæµç¨‹ç·¨æ’ï¼š

**å·¥ä½œæµç¨‹å”èª¿å™¨**
```typescript
import { EventEmitter } from 'events';
import { Logger } from 'winston';

interface WorkflowStep {
  name: string;
  type: 'parallel' | 'sequential';
  steps?: WorkflowStep[];
  action?: () => Promise<any>;
  retries?: number;
  timeout?: number;
  condition?: () => boolean;
  onError?: 'fail' | 'continue' | 'retry';
}

export class WorkflowOrchestrator extends EventEmitter {
  constructor(
    private logger: Logger,
    private config: WorkflowConfig
  ) {
    super();
  }
  
  async execute(workflow: WorkflowStep): Promise<WorkflowResult> {
    const startTime = Date.now();
    const result: WorkflowResult = {
      success: true,
      steps: [],
      duration: 0
    };
    
    try {
      await this.executeStep(workflow, result);
    } catch (error) {
      result.success = false;
      result.error = error;
      this.emit('workflow:failed', result);
    }
    
    result.duration = Date.now() - startTime;
    this.emit('workflow:completed', result);
    
    return result;
  }
  
  private async executeStep(
    step: WorkflowStep,
    result: WorkflowResult,
    parentPath: string = ''
  ): Promise<void> {
    const stepPath = parentPath ? `${parentPath}.${step.name}` : step.name;
    
    this.emit('step:start', { step: stepPath });
    
    // æª¢æŸ¥æ¢ä»¶
    if (step.condition && !step.condition()) {
      this.logger.info(`ç”±æ–¼æ¢ä»¶ï¼Œè·³éæ­¥é©Ÿ ${stepPath}`);
      this.emit('step:skipped', { step: stepPath });
      return;
    }
    
    const stepResult: StepResult = {
      name: step.name,
      path: stepPath,
      startTime: Date.now(),
      success: true
    };
    
    try {
      if (step.action) {
        // åŸ·è¡Œå–®ä¸€å‹•ä½œ
        await this.executeAction(step, stepResult);
      } else if (step.steps) {
        // åŸ·è¡Œå­æ­¥é©Ÿ
        if (step.type === 'parallel') {
          await this.executeParallel(step.steps, result, stepPath);
        } else {
          await this.executeSequential(step.steps, result, stepPath);
        }
      }
      
      stepResult.endTime = Date.now();
      stepResult.duration = stepResult.endTime - stepResult.startTime;
      result.steps.push(stepResult);
      
      this.emit('step:complete', { step: stepPath, result: stepResult });
    } catch (error) {
      stepResult.success = false;
      stepResult.error = error;
      result.steps.push(stepResult);
      
      this.emit('step:failed', { step: stepPath, error });
      
      if (step.onError === 'fail') {
        throw error;
      }
    }
  }
  
  private async executeAction(
    step: WorkflowStep,
    stepResult: StepResult
  ): Promise<void> {
    const timeout = step.timeout || this.config.defaultTimeout;
    const retries = step.retries || 0;
    
    let lastError: Error;
    
    for (let attempt = 0; attempt <= retries; attempt++) {
      try {
        const result = await Promise.race([
          step.action!(),
          this.createTimeout(timeout)
        ]);
        
        stepResult.output = result;
        return;
      } catch (error) {
        lastError = error as Error;
        
        if (attempt < retries) {
          this.logger.warn(`æ­¥é©Ÿ ${step.name} å¤±æ•—ï¼Œé‡è©¦ ${attempt + 1}/${retries}`);
          await this.delay(this.calculateBackoff(attempt));
        }
      }
    }
    
    throw lastError!;
  }
  
  private async executeParallel(
    steps: WorkflowStep[],
    result: WorkflowResult,
    parentPath: string
  ): Promise<void> {
    await Promise.all(
      steps.map(step => this.executeStep(step, result, parentPath))
    );
  }
  
  private async executeSequential(
    steps: WorkflowStep[],
    result: WorkflowResult,
    parentPath: string
  ): Promise<void> {
    for (const step of steps) {
      await this.executeStep(step, result, parentPath);
    }
  }
  
  private createTimeout(ms: number): Promise<never> {
    return new Promise((_, reject) => {
      setTimeout(() => reject(new Error(`è¶…æ™‚ ${ms} æ¯«ç§’å¾Œ`)), ms);
    });
  }
  
  private calculateBackoff(attempt: number): number {
    return Math.min(1000 * Math.pow(2, attempt), 30000);
  }
  
  private delay(ms: number): Promise<void> {
    return new Promise(resolve => setTimeout(resolve, ms));
  }
}

// å·¥ä½œæµç¨‹å®šç¾©ç¯„ä¾‹
export const deploymentWorkflow: WorkflowStep = {
  name: 'éƒ¨ç½²',
  type: 'sequential',
  steps: [
    {
      name: 'éƒ¨ç½²å‰',
      type: 'parallel',
      steps: [
        {
          name: 'å‚™ä»½è³‡æ–™åº«',
          action: async () => {
            // å‚™ä»½è³‡æ–™åº«
          },
          timeout: 300000 // 5 åˆ†é˜
        },
        {
          name: 'å¥åº·æª¢æŸ¥',
          action: async () => {
            // æª¢æŸ¥ç³»çµ±å¥åº·ç‹€æ³
          },
          retries: 3
        }
      ]
    },
    {
      name: 'éƒ¨ç½²',
      type: 'sequential',
      steps: [
        {
          name: 'è—ç¶ éƒ¨ç½²åˆ‡æ›',
          action: async () => {
            // å°‡æµé‡åˆ‡æ›åˆ°æ–°ç‰ˆæœ¬
          },
          onError: 'retry',
          retries: 2
        },
        {
          name: 'å†’ç…™æ¸¬è©¦',
          action: async () => {
            // åŸ·è¡Œå†’ç…™æ¸¬è©¦
          },
          onError: 'fail'
        }
      ]
    },
    {
      name: 'éƒ¨ç½²å¾Œ',
      type: 'parallel',
      steps: [
        {
          name: 'é€šçŸ¥åœ˜éšŠ',
          action: async () => {
            // ç™¼é€é€šçŸ¥
          },
          onError: 'continue'
        },
        {
          name: 'æ›´æ–°ç›£æ§',
          action: async () => {
            // æ›´æ–°ç›£æ§å„€è¡¨æ¿
          }
        }
      ]
    }
  ]
};
```

## è¼¸å‡ºæ ¼å¼

1. **å·¥ä½œæµç¨‹åˆ†æ**ï¼šç¾æœ‰æµç¨‹å’Œè‡ªå‹•åŒ–æ©Ÿæœƒ
2. **CI/CD ç®¡é“**ï¼šå®Œæ•´çš„ GitHub Actions/GitLab CI é…ç½®
3. **ç™¼å¸ƒè‡ªå‹•åŒ–**ï¼šèªç¾©åŒ–ç‰ˆæœ¬æ§åˆ¶å’Œç™¼å¸ƒå·¥ä½œæµç¨‹
4. **é–‹ç™¼è‡ªå‹•åŒ–**ï¼šé æäº¤é‰¤å­å’Œè¨­å®šè…³æœ¬
5. **åŸºç¤è¨­æ–½è‡ªå‹•åŒ–**ï¼šTerraform å’Œ Kubernetes å·¥ä½œæµç¨‹
6. **å®‰å…¨è‡ªå‹•åŒ–**ï¼šæƒæå’Œåˆè¦æ€§å·¥ä½œæµç¨‹
7. **æ–‡ä»¶ç”Ÿæˆ**ï¼šè‡ªå‹•åŒ–æ–‡ä»¶å’Œåœ–è¡¨
8. **å·¥ä½œæµç¨‹ç·¨æ’**ï¼šè¤‡é›œå·¥ä½œæµç¨‹ç®¡ç†
9. **ç›£æ§æ•´åˆ**ï¼šè‡ªå‹•åŒ–è­¦å ±å’Œå„€è¡¨æ¿
10. **å¯¦æ–½æŒ‡å—**ï¼šé€æ­¥è¨­å®šèªªæ˜

å°ˆæ³¨æ–¼å»ºç«‹å¯é ã€å¯ç¶­è­·çš„è‡ªå‹•åŒ–ï¼Œä»¥æ¸›å°‘æ‰‹å‹•å·¥ä½œï¼ŒåŒæ™‚ä¿æŒå“è³ªå’Œå®‰å…¨æ¨™æº–ã€‚
